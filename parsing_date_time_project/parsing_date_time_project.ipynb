{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Date and Time - Parsing and Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning points:\n",
    "* Classes\n",
    "    * date class, timedelta class, datetime class\n",
    "* Formatting and Parsing methods\n",
    "    * isoformat(), strftime(), strptime()\n",
    "* Understanding timestamp\n",
    "* Doing Arithmetic with dates and times\n",
    "    * timedelta class idea\n",
    "    * duration idea\n",
    "* Time zones\n",
    "    * **naive** datetime vs datetime with timezone\n",
    "    * Time zone database\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Class, Timedelta Class (Parsing Dates - no 'time' yet)\n",
    "* Goal 1: Working with `date class` and `timedelta class`\n",
    "* Goal 2: Doing Arithmetics with dates\n",
    "\n",
    "*The idea when ONLY working with `date` (and not with `time` yet) is to have only an object of `datetime.date` type. \n",
    "\n",
    "* Creating a date object and accessing its attributes\n",
    "        * import the `date class` from the `datetime package`\n",
    "    * `from datetime import date`\n",
    "        * Start by creating a `date` object by instantiating it from the `date` class. Put them into a list.\n",
    "            * my_date_object_as_list_of_date_objects = [date(2025, 1, 22), date(2024, 1, 1)]\n",
    "        * You can use attributes on this object (e.g.: `.year`) to access its individual components\n",
    "            * my_date_object_as_list_of_date_objects[0].year -> 2025\n",
    "        * You can also use methods on this object (e.g.: `.weekday()`) to access its individual components\n",
    "            * my_date_object_as_list_of_date_objects[0].weekday() -> 2 (refers to Wednesday because Monday is 0)\n",
    "        * You can use other methods\n",
    "            * e.g.: min(my_date_object_as_list_of_date_objects) -> 2024-01-01\n",
    "    * `from datetime import timedelta`\n",
    "        * If we add/subtract dates, you get a `timedelta` object\n",
    "            * simple way: \n",
    "                * object_d2 = date(2024, 1, 30), object_d1 = date(2024, 1, 1) \n",
    "                * time_range_object =  object_d2 - object_d1\n",
    "                * You have to access the object's component: time_range_object.days -> 29\n",
    "            * We can also start with a timedelta object\n",
    "                * my_timedelta_object = timedelta(days=29) \n",
    "                * object_d1 + my_timedelta_object -> 2024-30-01\n",
    "    * Putting Dates as Strings\n",
    "        * Use cases:\n",
    "            * _put dates as filenames to organize folders_\n",
    "            * _export the dates to excel or CSV_\n",
    "        * In both cases, the idea is to FORMAT!\n",
    "        * ISO 8601 format (`YYYY-MM-DD`) using `isoformat()` method and Other Formats using `strftime()` method on the `date` object\n",
    "            * Put the date object in a list already in ISO 8601 format:\n",
    "                * my_object_as_list_of_date_objects_iso = [date(2025, 1, 22).isoformat()) date(2024, 1, 1).isoformat()] \n",
    "            * Pass a format string of your choice:\n",
    "                * object_d1_formatted = date(2024, 01, 01).strftime(\"%Y\") -> 2024\n",
    "                * object_d1_formatted = date(2024, 01, 01).strftime(\"Year is: %Y\") -> Year is: 2024\n",
    "                * object_d1_formatted = date(2024, 01, 01).strftime(\"%Y/%m/%d\") -> 2024/01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date Class\n",
    "from datetime import date\n",
    "\n",
    "my_date_object_as_list_of_date_objects = [date(2025, 1, 22), date(2024, 1, 1)]\n",
    "\n",
    "print(\"The object 'date(2025, 1, 22)' has the type: \", type(my_date_object_as_list_of_date_objects[0]))\n",
    "\n",
    "my_date_object = date(2025, 1, 22)\n",
    "\n",
    "print(\"The object from the list is printed in this way: \", my_date_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Class, Timedelta Class (Parsing Dates - now with 'time')\n",
    "* Goal 1: Working with `datetime class` and `replace()`\n",
    "* Goal 2: Parsing string dates to datetime\n",
    "* Goal 3: Understanding `timestamp`\n",
    "\n",
    "* Creating a datetime object and accessing its attributes\n",
    "        * import the `datetime class` from the `datetime package`\n",
    "    * `from datetime import datetime`\n",
    "        * E.g.: 2024-01-01 18:30:59 (precision of 0.5 seconds or 500000 microseconds\n",
    "        * Precision is importanto for finance, for example.\n",
    "        * my_datetime_object = datetime(2024, 1, 1, 18, 30, 59, 500000)\n",
    "    * `replace()` method\n",
    "        * If you want to **replace** some of the components for new ones:\n",
    "            * E.g.: 2024-01-01 18:00:00\n",
    "            * my_datetime_object_with_new_hour = datetime(minute=0, second=0, microsecond=0)\n",
    "    * Parsing string dates date using `strftime()` and `strptime()`\n",
    "        * E.g.: `\"2024-01-01 18:30:59\"` as **string**\n",
    "            * \"2024-01-01 18:30:59\" \n",
    "            * my_datetime_object_from_string_to_datetime = datetime.strptime(\"2024-01-01 18:30:59\", \"%m/%d/%Y %H:%M:%S\")\n",
    "            * my_datetime_object_from_string_to_datetime -> 2024-01-01 18:30:59 (as datetime object)\n",
    "    * Timestamp\n",
    "        * _Computers store datetime information as the number of seconds since 1970-01-01 (when modern computers were born)_\n",
    "        * Converting from `timestamp` to `datetime`\n",
    "            * datetime.fromtimestamp(1704133859.0) -> 2024-01-01 18:30:59 (as datetime object)\n",
    "    * Duration and timedeltas\n",
    "        * If we add/subtract dates with time, you get a `timedelta` object\n",
    "        * simple way: \n",
    "            * object_d2_with_time = datetime(2024, 1, 1, 18, 30, 59), object_d1_with_time = date(2024, 1, 1, 18, 30, 9) \n",
    "            * time_range_object =  object_d2 - object_d1\n",
    "            * You have to access the object's component: time_range_object.total_seconds() -> 50\n",
    "        * We can also start with a timedelta object\n",
    "            * my_timedelta_object = timedelta(seconds=50) \n",
    "            * object_d1_with_time + my_timedelta_object -> 2024-01-01 18:30:59\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Zones\n",
    "* Goal 1: Working with `timezone class` and making `datetime` **aware** of a timezone\n",
    "* Goal 2: Handling time zones in 3 ways\n",
    "\n",
    "* Naive Datetime object\n",
    "    * An object can be aware or naive depending on whether it has timezone information.\n",
    "    * datetime(2024, 1, 1, 18, 30, 59) -> 2024-01-01 18:30:59\n",
    "        * There is not timezone attribute\n",
    "    * datetime(2024, 1, 1, 18, 30, 59, tzinfo=timezone(timedelta(hours=-2))) -> 2024-01-01 18:30:59-02:00\n",
    "\n",
    "* 3 Ways to Represent **non-naive** Time zones\n",
    "    * E.g.: 12:00 in UTC+2 = 10:00 in UTC \n",
    "        1) Imposing UTC+2 \n",
    "            * 12:00 in UTC+2 \n",
    "            * -> datetime(2024, 1, 1, 12, 00, 00, tzinfo = timezone(timedelta(hours=+2)))\n",
    "        2) Converting the time itself to the UTC you want \n",
    "            * 12:00 in UTC+2 = 10:00 in UTC\n",
    "            * -> datetime(2024, 1, 1, 12, 00, 00, tzinfo = timezone(timedelta(hours=+2))).astimezone(timezone.utc)\n",
    "        3) Automatic Time zones: \n",
    "            * Using the `tz` database to get the timezone you want\n",
    "            * 12:00 in UTC+2\n",
    "            * -> datetime(2024, 1, 1, 12, 00, 00, tzinfo = tz.gettz('America/New_York'))\n",
    "    * In the first case, we have the time of the clock in UTC+2\n",
    "    * In the second one, we have the same time of the clock in UTC\n",
    "    * In the third case, we have the time in the UTC we want by using the `tz` database\n",
    "    * Creating a timezone object \n",
    "        * `from datetime import timezone`\n",
    "            * Changing a `datetime` object to a specific timezone using `tzinfo` attribute \n",
    "                * Creating a timezone object with `timedelta`\n",
    "                    * timezone_object_utc_minus5 = timezone(timedelta(hours=-5)) - New York time zone\n",
    "                    * my_datetime_object_with_timezone = datetime(2024, 1, 1, 18, 30, 59, tzinfo = timezone_object_utc_minus5)\n",
    "                        * -> 2024-01-01 18:30:59-05:00\n",
    "    * Time zone Database\n",
    "        * Goal: to have *updated* time zone when it changes.\n",
    "        * A third way is to use database `tz` from `dateutil`package, as well as `gettz()`\n",
    "        * First, create a timezone object\n",
    "            * my_timezone_object = tz.gettz('America/New_York')\n",
    "        * Now, load it into the datetime object:\n",
    "            * my_datetime_object_with_timezone_from database = datetime(2024, 1, 1, 18, 30, 59, tzinfo = my_timezone_object) -> 2024-01-01 18:30:59-05:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madrid time zone object:  tzfile('Europe/Madrid')\n",
      "Naive datetime (assumed UTC): 2024-01-01 18:30:59\n",
      "Set to UTC datetime: 2024-01-01 18:30:59+00:00\n",
      "Converted to Madrid timezone: 2024-01-01 19:30:59+01:00\n"
     ]
    }
   ],
   "source": [
    "from dateutil import tz\n",
    "from datetime import datetime\n",
    "\n",
    "# Step 1: Create the timezone object for Europe/Madrid\n",
    "madrid_tz = tz.gettz('Europe/Madrid')\n",
    "print(\"Madrid time zone object: \", madrid_tz)\n",
    "\n",
    "# Step 2: Create a naive datetime object (assumed to be in UTC)\n",
    "my_naive_datetime_object = datetime(2024, 1, 1, 18, 30, 59)\n",
    "\n",
    "# Step 3: Mark the naive datetime as being in UTC\n",
    "utc_datetime_object = my_naive_datetime_object.replace(tzinfo=tz.UTC)\n",
    "\n",
    "# Step 4: Convert the UTC datetime to the Madrid timezone\n",
    "madrid_datetime_object = utc_datetime_object.astimezone(madrid_tz)\n",
    "\n",
    "# Print the results\n",
    "print(\"Naive datetime (assumed UTC):\", my_naive_datetime_object)\n",
    "print(\"Set to UTC datetime:\", utc_datetime_object)\n",
    "print(\"Converted to Madrid timezone:\", madrid_datetime_object)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Zone Database\n",
    "* Goal 1: Working with `timezone class` and making `datetime` **aware** of a timezone\n",
    "* Goal 2: Handling time zones \n",
    "\n",
    "* Naive Datetime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our dataset\n",
    "\n",
    "| Column                   | Description                                                                      |\n",
    "|------------------------- |--------------------------------------------------------------------------------- |\n",
    "| `student_id`             | A unique ID for each student.                                                    |\n",
    "| `city`                   | A code for the city the student lives in.                                        |\n",
    "| `city_development_index` | A scaled development index for the city.                                         |\n",
    "| `gender`                 | The student's gender.                                                            |\n",
    "| `relevant_experience`    | An indicator of the student's work relevant experience.                          |\n",
    "| `enrolled_university`    | The type of university course enrolled in (if any).                              |\n",
    "| `education_level`        | The student's education level.                                                   |\n",
    "| `major_discipline`       | The educational discipline of the student.                                       |\n",
    "| `experience`             | The student's total work experience (in years).                                  |\n",
    "| `company_size`           | The number of employees at the student's current employer.                       |\n",
    "| `company_type`           | The type of company employing the student.                                       |\n",
    "| `last_new_job`           | The number of years between the student's current and previous jobs.             |\n",
    "| `training_hours`         | The number of hours of training completed.                                       |\n",
    "| `job_change`             | An indicator of whether the student is looking for a new job (`1`) or not (`0`). |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "ds_jobs = pd.read_csv(\"C:/Users/caiov/OneDrive - UCLA IT Services/Documentos/DataScience/Repositories/cleaning-categorical-data-best-practices/data/customer_not_efficient.csv\")\n",
    "\n",
    "# View the dataset\n",
    "ds_jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of ds_jobs for transforming\n",
    "ds_jobs_transformed = ds_jobs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_jobs_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numeric Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Numeric Columns\n",
    "# Note: job_change should be a categorical column and not a numeric column\n",
    "\n",
    "numeric_columns = ['student_id', 'city_development_index', 'training_hours']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Procedures\n",
    "\n",
    "| **Integer Columns**               | **Float Columns**             |\n",
    "|-----------------------------------|-------------------------------|\n",
    "| Store as 32-bit integers (`int32`) | Store as 16-bit floats (`float16`) |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the numeric columns according to the table above\n",
    "\n",
    "for col in ds_jobs_transformed[numeric_columns]:\n",
    "    if pd.api.types.is_integer_dtype(ds_jobs_transformed[col]):\n",
    "        ds_jobs_transformed[col] = ds_jobs_transformed[col].astype('int32')\n",
    "    elif pd.api.types.is_float_dtype(ds_jobs_transformed[col]):\n",
    "        ds_jobs_transformed[col] = ds_jobs_transformed[col].astype('float16')\n",
    "\n",
    "print(ds_jobs_transformed[numeric_columns].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of Categorical Columns\n",
    "categorical_columns = list(ds_jobs_transformed.select_dtypes(include=['object', 'category']).columns)\n",
    "\n",
    "# Including `job_change` in the list of categorical columns\n",
    "categorical_columns = categorical_columns + ['job_change']\n",
    "\n",
    "print(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_jobs_transformed[categorical_columns].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Categorical Columns by its nature\n",
    "ls_categorical_bool = ['relevant_experience', 'job_change']\n",
    "ls_categorical_with_order = ['enrolled_university', 'education_level', 'experience', 'company_size', 'last_new_job']\n",
    "ls_categorical_no_order = ['city', 'gender', 'major_discipline', 'company_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Procedures\n",
    "\n",
    "| **Converting Categorical Data**                                                                                  |\n",
    "|------------------------------------------------------------------------------------------------------------------|\n",
    "| (Two-factor categories) Data w/ **2 categories**: yes/no → Convert to `bool`                                     |\n",
    "| (Ordinal Data) Data w/ **> 2 categories** and **natural ordering** → Convert to `ordered category`               |\n",
    "| (Nominal data) Data w/ **few unique values** and **no natural ordering** → Convert to `category`                 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-factor Categories (mapping to boolean)\n",
    "print(\"relevant_experience: \", ds_jobs_transformed['relevant_experience'].unique())\n",
    "print(\"job_change: \", ds_jobs_transformed['job_change'].unique())\n",
    "\n",
    "ds_jobs_transformed['relevant_experience'] = ds_jobs_transformed['relevant_experience'].map({'Has relevant experience': True, 'No relevant experience': False})\n",
    "ds_jobs_transformed['job_change'] = ds_jobs_transformed['job_change'].map({1: True, 0: False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"relevant_experience: \", ds_jobs_transformed['relevant_experience'].unique())\n",
    "print(\"job_change: \", ds_jobs_transformed['job_change'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal Data (converting to \"ordered category\")\n",
    "\n",
    "# enrolled_university\n",
    "print(\"enrolled_university: \", ds_jobs_transformed['enrolled_university'].unique())\n",
    "\n",
    "ls_enrolled_university_order = ['no_enrollment', 'Part time course', 'Full time course']\n",
    "\n",
    "ds_jobs_transformed['enrolled_university'] = pd.Categorical(ds_jobs_transformed['enrolled_university'], categories=ls_enrolled_university_order, ordered=True)\n",
    "\n",
    "print(\"enrolled_university: \", ds_jobs_transformed['enrolled_university'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# education_level\n",
    "\n",
    "print(\"education_level: \", ds_jobs_transformed['education_level'].unique())\n",
    "\n",
    "ls_education_level_order = ['Primary School', 'High School', 'Graduate', 'Masters', 'Phd']\n",
    "\n",
    "ds_jobs_transformed['education_level'] = pd.Categorical(ds_jobs_transformed['education_level'], categories=ls_education_level_order, ordered=True)\n",
    "\n",
    "print(\"education_level: \", ds_jobs_transformed['education_level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experience\n",
    "print(\"experience: \", ds_jobs_transformed['experience'].unique())\n",
    "\n",
    "ls_experience_order = ['<1', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '>20']\n",
    "\n",
    "ds_jobs_transformed['experience'] = pd.Categorical(ds_jobs_transformed['experience'], categories=ls_experience_order, ordered=True)\n",
    "\n",
    "print(\"experience: \", ds_jobs_transformed['experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# company_size\n",
    "print(\"company_size: \", ds_jobs_transformed['company_size'].unique())\n",
    "\n",
    "ls_company_size_order = ['<10', '10/49', '50-99', '100-500', '500-999', '1000-4999', '5000-9999', '10000+']\n",
    "\n",
    "ds_jobs_transformed['company_size'] = pd.Categorical(ds_jobs_transformed['company_size'], categories=ls_company_size_order, ordered=True)\n",
    "\n",
    "print(\"company_size: \", ds_jobs_transformed['company_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last_new_job\n",
    "print(\"last_new_job: \", ds_jobs_transformed['last_new_job'].unique())\n",
    "\n",
    "ls_last_new_job_order = ['never', '1', '2', '3', '4', '>4']\n",
    "\n",
    "ds_jobs_transformed['last_new_job'] = pd.Categorical(ds_jobs_transformed['last_new_job'], categories=ls_last_new_job_order, ordered=True)\n",
    "\n",
    "print(\"last_new_job: \", ds_jobs_transformed['last_new_job'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nominal Data (converting to \"category\")\n",
    "\n",
    "ls_categorical_no_order = ['city', 'gender', 'major_discipline', 'company_type']\n",
    "\n",
    "for col in ls_categorical_no_order:\n",
    "    ds_jobs_transformed[col] = ds_jobs_transformed[col].astype('category')\n",
    "\n",
    "# Check the data types of the transformed dataset\n",
    "ds_jobs_transformed[ls_categorical_no_order].info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Goal\n",
    "\n",
    "This recruitment company wants to focus on:\n",
    "* more experienced professionals\n",
    "* enterprise companies\n",
    "\n",
    "Therefore, the DataFrame should be filtered to only contain:\n",
    "* 'experience' >= 10 year\n",
    "* 'company_size' >= 1000 employees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering dataset for business goals\n",
    "ds_jobs_transformed = ds_jobs_transformed[\n",
    "    (ds_jobs_transformed['experience'] >= '10') & \n",
    "    (ds_jobs_transformed['company_size'] >= '1000-4999')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking Efficiency: Memory Usage (Old Dataframe vs. New Dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Original DataFrame memory usage: {ds_jobs.memory_usage(deep=True).sum() / 1024 ** 2:.2f} MB\")\n",
    "print(f\"Transformed DataFrame memory usage: {ds_jobs_transformed.memory_usage(deep=True).sum() / 1024 ** 2:.2f} MB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
